{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luke Waninger\n",
    "#### 25 May 2018 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T05:43:51.929321Z",
     "start_time": "2018-05-28T05:43:50.807231Z"
    }
   },
   "outputs": [],
   "source": [
    "from H7_source import *\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "exp   = np.exp\n",
    "ident = np.identity\n",
    "na    = np.newaxis\n",
    "norm  = np.linalg.norm\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The gradient $\\triangledown F(\\alpha)$ of $F$\n",
    "for a kernel based support vector machine can be shown to be..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\triangledown F(\\alpha) = 1/n \\sum_{i=1}^n \\triangledown l(y_i, (K\\alpha)_i) + 2\\lambda K \\alpha$\n",
    "\n",
    "\n",
    "\n",
    "$\n",
    "\\triangledown l(y,t) =\n",
    "\t\\begin{cases}\n",
    "        0 \\hspace{55pt}  yt > 1 + h \\\\\n",
    "        -y_i x_i \\frac{1+h-yt}{2h} \\hspace{18pt}  |1-yt| \\le h \\\\\n",
    "        -y_i x_i \\hspace{40pt}  yt < 1-h\n",
    "\t\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the graham and kernel matrices for a Gaussian (RBF) and polynomial kernel\n",
    "I decided to encapsulate these functions into one class each for radial and polynomial kernels for readability and code reuse. The $\\texttt{compute}$ function calculates and returns the requested kernel for any set of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T05:43:51.944097Z",
     "start_time": "2018-05-28T05:43:51.932075Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class k_radialrbf(Kernel):\n",
    "    def __init__(self, sigma):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'rbf({self.sigma})'\n",
    "\n",
    "    def compute(self, x, xp=None):\n",
    "        sigma = self.sigma\n",
    "        xp = x if xp is None else xp\n",
    "\n",
    "        def norm(mat):\n",
    "            return np.linalg.norm(mat, axis=1)\n",
    "\n",
    "        return exp(-1/(2*sigma**2) * ((norm(x)** 2)[:, na] + (norm(xp)**2)[na, :]-2*(x @ xp.T)))\n",
    "\n",
    "\n",
    "class k_polynomial(Kernel):\n",
    "    def __init__(self, degree, b=1.):\n",
    "        super().__init__()\n",
    "        self.degree = degree\n",
    "        self.b = b\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'polynomial({self.degree})'\n",
    "\n",
    "    def compute(self, x, xp=None):\n",
    "        xp = x if xp is None else xp\n",
    "\n",
    "        return (x @ xp.T + self.b)**self.degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using scikit learn's builtin Digits dataset, download and standardize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T05:43:52.111780Z",
     "start_time": "2018-05-28T05:43:51.946641Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "\n",
    "scalar  = StandardScaler().fit(x_train)\n",
    "x_train = scalar.transform(x_train)\n",
    "x_test  = scalar.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The support vector machine: $\\texttt{mysvm}$\n",
    "Again, I chose to implement this using OOP so I could encapsulate the SVM, and other helper functions in a single object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T05:43:52.136814Z",
     "start_time": "2018-05-28T05:43:52.116588Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MySVM(Estimator):\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'SVM(kernel={self.kernel})'\n",
    "    \n",
    "    @staticmethod\n",
    "    def gradient(k, y, beta, l, h=0.5):\n",
    "        n, d = k.shape\n",
    "        lg = np.zeros([n, d])\n",
    "\n",
    "        yk = y *(k @ beta)\n",
    "        mask = np.abs(1 - yk)\n",
    "\n",
    "        lg[mask <= h] = ((1/(2*h)) * ((1 + h-yk)[:, na]) * (-y[:, na] * k))[mask <= h]\n",
    "        lg[yk < 1-h]  = (-y[:, na] * k)[yk < 1-h]\n",
    "\n",
    "        return np.array(np.sum(lg, axis=0)/n + 2*l*beta)\n",
    "    \n",
    "    def fgrad(self, k, y, l, eta=1., max_iter=100):\n",
    "        n, d  = k.shape\n",
    "        b0    = np.zeros(d)\n",
    "        theta = np.copy(b0)\n",
    "        grad  = self.gradient(k, y, b0, l)\n",
    "\n",
    "        i = 0\n",
    "        while i < max_iter and not np.isclose(0, eta):\n",
    "            eta = backtracking(k, y, b0, l, eta, self.gradient, self.objective)\n",
    "\n",
    "            b1 = theta - eta*grad\n",
    "            theta = b1 + (i/(i+3))*(b1-b0)\n",
    "            grad  = self.gradient(k, y, theta, l)\n",
    "            b0 = b1\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        return b0\n",
    "    \n",
    "    @staticmethod\n",
    "    def objective(k, y, l, beta, h=0.5):\n",
    "        n, d = k.shape\n",
    "        loss = np.zeros(n)\n",
    "        yk = y * (k @ beta)\n",
    "        mask = np.abs(1 - yk)\n",
    "\n",
    "        loss[mask <= h] = ((1 + h-yk)**2 / (4*h))[mask <= h]\n",
    "        loss[yk < 1-h] = (1 - yk)[yk < 1-h]\n",
    "\n",
    "        return np.sum(loss)/n + l*norm(beta)**2\n",
    "\n",
    "    def predict(self, kp, beta):\n",
    "        return [1 if ki @ beta.T > 0 else -1 for ki in kp]\n",
    "    \n",
    "    def predict_proba(self, kp, beta):\n",
    "        return [ki @ beta.T for ki in kp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the SVM with the huberized hinge loss and an order 7 polynomial kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "running one vs rest with a polynomial kernel of degree 7 with $\\lambda$=1 gives a horrible validation error: $\\approx$ 0.518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T05:44:34.715164Z",
     "start_time": "2018-05-28T05:43:52.141429Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'track_bar.<locals>.track_it'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-99cc6508120c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mkernl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_polynomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mOVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMySVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\git\\DATA558_StatisticalML\\homework\\H7_source.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, xv, yv, earg, pbar)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;31m# setup a progress bar if none was given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[0mpb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrack_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpears\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'fitting {self}'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpbar\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# fit each child classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\git\\DATA558_StatisticalML\\homework\\H7_source.py\u001b[0m in \u001b[0;36mtrack_bar\u001b[1;34m(total, desc)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[0mtrackq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQueue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m     \u001b[0mmultiprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_it\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrackq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrackq\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'track_bar.<locals>.track_it'"
     ]
    }
   ],
   "source": [
    "kernl = k_polynomial(7)\n",
    "OVR(MySVM(kernl), n_jobs=-1).fit(x_train, y_train, x_test, y_test, 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using cross-validation we see close to a performance improvement of around 9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T05:46:21.841381Z",
     "start_time": "2018-05-28T05:44:34.738216Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ovr = OVR(MySVM(kernl), n_jobs=-1)\n",
    "cv(x_train, y_train, ovr, eargs=np.linspace(.001, 1., 5), nfolds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare the performance of kernel SVMs\n",
    "It quickly becomes clear the 7-degree polynomial kernel is a horrible choice. Below, I run a series of OVO polynomial and radial kernels that all show much better performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T05:56:58.892691Z",
     "start_time": "2018-05-28T05:46:21.853232Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernels = [\n",
    "    k_polynomial(1),\n",
    "    k_polynomial(3),\n",
    "    k_polynomial(5),\n",
    "    k_radialrbf(1),\n",
    "    k_radialrbf(5),\n",
    "    k_radialrbf(10)\n",
    "]\n",
    "\n",
    "for kernl in kernels:\n",
    "    ovr, eargs = OVR(MySVM(kernl), n_jobs=-1), np.linspace(.001, 1., 5)\n",
    "    cv(x_train, y_train, ovr, eargs, nfolds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking my OvO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T05:56:58.920579Z",
     "start_time": "2018-05-28T05:56:58.896520Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oja(x, t=1., max_iter=50):    \n",
    "    n, d = x.shape\n",
    "    w1  = np.random.normal(size=d)\n",
    "    w1 /= norm(w1)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        w1 = w1 + t*(x.T @ x @ w1)\n",
    "        w1 = w1/norm(w1)\n",
    "        t  = 1/(i+1)\n",
    "\n",
    "    w1 = w1[:, na]\n",
    "    C  = x.T @ x @ (ident(d) - w1 @ w1.T)\n",
    "    \n",
    "    w2 = np.random.normal(size=d)\n",
    "    w2 = w2/norm(w2)\n",
    "    for i in range(max_iter):\n",
    "        w2 = w2 + t * (C @ w2)\n",
    "        w2 = w2/norm(w2)\n",
    "        t  = 1/(i+1)\n",
    "\n",
    "    w2 = w2[:, na]\n",
    "    return np.concatenate([x@w1, x@w2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oja_r(wp, n, t, max_iter):\n",
    "    if n == end:\n",
    "        return None\n",
    "    \n",
    "    n, d = x.shape\n",
    "    w = np.random.norm(size=d)\n",
    "    w /= norm(w1)\n",
    "    \n",
    "    C  = x.T @ x @ (ident(d) - wp @ wp.T)\n",
    "    for i in range(max_iter):\n",
    "        w = w + t*(x.T @ x @ w)\n",
    "        w = w/norm(w)\n",
    "        t = 1/(i+3)\n",
    "    \n",
    "    w = w[:, na]\n",
    "    return np.concatentate([x@w, oja_r(w, n+1, t, max_iter)], axis=1).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate a simulated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T05:56:58.939537Z",
     "start_time": "2018-05-28T05:56:58.926477Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_k(n, m, scale):\n",
    "    def gen_ki(m, s):\n",
    "        return np.random.normal(m, s, 1)\n",
    "    \n",
    "    start = n*scale\n",
    "    means = np.random.uniform(start, start+m, m)\n",
    "    np.random.shuffle(means)\n",
    "\n",
    "    return np.array([[gen_ki(mi, 25) for mi in means] for i in range(n)]).reshape((n, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run my oja and plot vs scikit's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T06:06:00.024994Z",
     "start_time": "2018-05-28T06:05:59.919666Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_obs, n_feat, n_klass = 30, 60, 3\n",
    "x = np.array([gen_k(n_obs, n_feat, i) for i in range(n_klass)]).reshape((n_obs*n_klass, n_feat))\n",
    "\n",
    "mykit = oja(x)\n",
    "scikt = PCA().fit_transform(X=x)\n",
    "\n",
    "pca_plot([mykit, scikt], n_obs, n_klass)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
